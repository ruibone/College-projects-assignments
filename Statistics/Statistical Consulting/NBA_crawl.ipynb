{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T13:19:14.915188Z",
     "start_time": "2021-11-10T13:19:14.901343Z"
    }
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Game Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T13:19:15.840618Z",
     "start_time": "2021-11-10T13:19:15.814037Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basic_crawler(soup, year):\n",
    "    \n",
    "    table_index = 4 if year >= 2015 else 2\n",
    "    game_header = [th.getText() for th in soup.findAll('table')[4].findAll('th', class_ = 'poptip center')]\n",
    "    game_table = soup.findAll('table')[table_index]\n",
    "    game_row = game_table.findAll('tr')[1:]\n",
    "    game_data = [[i.getText() for i in game_row[j].findAll('td')] for j in range(len(game_row))]\n",
    "    per_game = pd.DataFrame(game_data, columns = game_header)\n",
    "    per_game.Team = per_game.Team.replace('Los Angeles Lakers*', 'LA Lakers temp')\n",
    "    per_game.Team = per_game.Team.replace('Los Angeles Lakers', 'LA Lakers temp')\n",
    "    per_game.Team = per_game.Team.replace('Los Angeles Clippers*', 'LA Clippers temp')\n",
    "    per_game.Team = per_game.Team.replace('Los Angeles Clippers', 'LA Clippers temp')\n",
    "    game_citys = [x[:-1] for x in per_game.Team.str.strip('*').str.split(' ')]\n",
    "    for index, city in enumerate(game_citys):\n",
    "            game_citys[index] = city[0] + ' ' + city[1] if len(city) > 1 else city[0]\n",
    "    per_game.Team = game_citys\n",
    "    per_game.Team = per_game.Team.replace('Portland Trail', 'Portland')\n",
    "    game_select = ['Team', 'FG', 'FG%', '3P', '3P%', '2P', '2P%', 'FT', 'FT%', 'ORB', 'DRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
    "    game_done = per_game[game_select]\n",
    "    for i in game_select[1:]:\n",
    "        game_done[i] = pd.to_numeric(game_done[i])\n",
    "    game_done = game_done.sort_values(by = 'Team').reset_index(drop = True)\n",
    "    game_done['Year'] = year\n",
    "    \n",
    "    return game_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T13:19:16.791646Z",
     "start_time": "2021-11-10T13:19:16.779680Z"
    }
   },
   "outputs": [],
   "source": [
    "def advanced_crawler(soup, year):\n",
    "    \n",
    "    table_index = 10 if year >= 2015 else 8\n",
    "    ad_table = soup.findAll('table')[table_index]\n",
    "    ad_header = [i.getText() for i in ad_table.findAll('tr')[1].findAll('th', class_ = \n",
    "                                                                        ['poptip center', 'poptip sort_default_asc center'])]\n",
    "    ad_row = ad_table.findAll('tr')[1:]\n",
    "    ad_data = [[i.getText() for i in ad_row[j].findAll('td')] for j in range(1, len(ad_row))]\n",
    "    advanced = pd.DataFrame(ad_data, columns = ad_header)\n",
    "    advanced.Team = advanced.Team.replace('Los Angeles Lakers*', 'LA Lakers temp')\n",
    "    advanced.Team = advanced.Team.replace('Los Angeles Lakers', 'LA Lakers temp')\n",
    "    advanced.Team = advanced.Team.replace('Los Angeles Clippers*', 'LA Clippers temp')\n",
    "    advanced.Team = advanced.Team.replace('Los Angeles Clippers', 'LA Clippers temp')\n",
    "    advanced.Team = advanced.Team.replace('Portland Trail', 'Portland')\n",
    "    ad_citys = [x[:-1] for x in advanced.Team.str.strip('*').str.split(' ')]\n",
    "    for index, city in enumerate(ad_citys):\n",
    "            ad_citys[index] = city[0] + ' ' + city[1] if len(city) > 1 else city[0]\n",
    "    advanced.Team = ad_citys\n",
    "    advanced.Team = advanced.Team.replace('Portland Trail', 'Portland')\n",
    "    ad_select = ['Team', 'Age', 'PW', 'PL', 'SOS', 'SRS', 'ORtg', 'DRtg', 'NRtg', 'Pace', 'TS%', 'W']\n",
    "    advanced_done = advanced[ad_select]\n",
    "    for i in ad_select[1:]:\n",
    "        advanced_done[i] = pd.to_numeric(advanced_done[i])\n",
    "    for x in ['W', 'NRtg']:\n",
    "        advanced_done[x][30] = advanced_done[x].mean()\n",
    "    advanced_done = advanced_done.sort_values(by = 'Team').reset_index(drop = True)\n",
    "    advanced_done['Year'] = year\n",
    "    \n",
    "    return advanced_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T13:37:36.099757Z",
     "start_time": "2021-11-10T13:37:36.077938Z"
    }
   },
   "outputs": [],
   "source": [
    "def salary_crawler(soup, year):\n",
    "    \n",
    "    header = [th.getText() for th in soup.findAll('thead')[0].findAll('td')]\n",
    "    row = soup.findAll('tr')\n",
    "    data = [[td.getText()[10: -8] for td in row[i].findAll('td')] for i in range(1, len(row))]\n",
    "    salary = pd.DataFrame(data, columns = header).iloc[:, 1:]\n",
    "    salary.Team = salary.Team.str.strip()\n",
    "    salary[f'{year}/{year-1999}(*)'] = salary[f'{year}/{year-1999}(*)'].str.strip('$')\n",
    "    salary = salary[['Team', f'{year}/{year-1999}(*)']]\n",
    "    cost = [int(x[0] + x[1] + x[2]) for x in salary[f'{year}/{year-1999}(*)'].str.split(',')]\n",
    "    salary['Salary'] = cost\n",
    "    salary.loc[30] = ['League', 'temp', salary.Salary.mean()]\n",
    "    salary['Salary'] = salary.Salary.astype(int)\n",
    "    salary_done = salary.drop(columns = f'{year}/{year-1999}(*)')\n",
    "    salary_done = salary_done.sort_values(by = 'Team').reset_index(drop = True)\n",
    "    salary_done['Year'] = year\n",
    "\n",
    "    return salary_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T13:37:48.884041Z",
     "start_time": "2021-11-10T13:37:39.301733Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darui Yen\\Anaconda3\\envs\\aging_test\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "<ipython-input-194-9386d9072147>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  advanced_done[x][30] = advanced_done[x].mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2012: 31 basic, 31 advanced ,31 salary.\n",
      "Year 2013: 62 basic, 62 advanced ,62 salary.\n",
      "Year 2014: 93 basic, 93 advanced ,93 salary.\n",
      "Year 2016: 124 basic, 124 advanced ,124 salary.\n",
      "Year 2017: 155 basic, 155 advanced ,155 salary.\n",
      "Year 2018: 186 basic, 186 advanced ,186 salary.\n"
     ]
    }
   ],
   "source": [
    "##### 2012-13 to 2018-19 (without 2015-16) #####\n",
    "target_year = list(range(2012, 2015)) + list(range(2016, 2019))\n",
    "\n",
    "basic_df = pd.DataFrame()\n",
    "advanced_df = pd.DataFrame()\n",
    "salary_df = pd.DataFrame()\n",
    "for i in target_year:\n",
    "    url_1 = f'https://www.basketball-reference.com/leagues/NBA_{i+1}.html'\n",
    "    html_1 = urlopen(url_1)\n",
    "    soup_1 = BeautifulSoup(html_1)\n",
    "    url_2 = f'https://hoopshype.com/salaries/{i}-{i+1}/'\n",
    "    html_2 = urlopen(url_2)\n",
    "    soup_2 = BeautifulSoup(html_2)\n",
    "    temp_basic = basic_crawler(soup_1, i)\n",
    "    temp_advanced = advanced_crawler(soup_1, i)\n",
    "    temp_salary = salary_crawler(soup_2, i)\n",
    "    basic_df = pd.concat([basic_df, temp_basic], axis = 0).reset_index(drop = True)\n",
    "    advanced_df = pd.concat([advanced_df, temp_advanced], axis = 0).reset_index(drop = True)\n",
    "    salary_df = pd.concat([salary_df, temp_salary], axis = 0).reset_index(drop = True)\n",
    "    print(f'Year {i}: {len(basic_df)} basic, {len(advanced_df)} advanced ,{len(salary_df)} salary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T13:37:51.228322Z",
     "start_time": "2021-11-10T13:37:51.202957Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_df = salary_df.merge(basic_df, on = ['Team', 'Year'], how = 'inner')\n",
    "all_data = temp_df.merge(advanced_df, on = ['Team', 'Year'], how = 'inner')\n",
    "west_list = ['Utah', 'Phoenix', 'Denver', 'LA Clippers', 'Dallas', 'Portland', 'LA Lakers', 'Memphis', 'Golden State',\n",
    "             'San Antonio', 'New Orleans', 'Sacramento', 'Minnesota', 'Oklahoma City', 'Houston']\n",
    "conference = []\n",
    "for i in all_data.Team:\n",
    "    if i in west_list:\n",
    "        conference.append('West')\n",
    "    elif i == 'League':\n",
    "        conference.append('Average')\n",
    "    else:\n",
    "        conference.append('East')\n",
    "all_data['Conference'] = conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T13:38:03.651614Z",
     "start_time": "2021-11-10T13:38:03.635620Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data.to_csv('NBA_done.csv')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:aging_test]",
   "language": "python",
   "name": "conda-env-aging_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
